# install.packages("igraph")
# install.packages("CINNA")

library(igraph)
library(CINNA)

# Load the PPI data
ppi <- read.delim("temp/string_interactions_short.tsv", header = TRUE, sep = "\t")
colnames(ppi)

# Create an igraph object from the edge list
ppi_graph <- graph_from_data_frame(ppi[, c("X.node1", "node2")], directed = FALSE)


# Extract the largest connected component (giant component)
components <- clusters(ppi_graph)
giant_component <- induced_subgraph(ppi_graph, which(components$membership == which.max(components$csize)))


# Identify available centrality measures for the network
available_measures <- proper_centralities(giant_component)

# Calculate centralities for all valid measures
centrality_scores <- calculate_centralities(giant_component)

# Filter out zero-length centrality vectors
centrality_scores_clean_list <- centrality_scores[sapply(centrality_scores, function(x) length(x) > 0)]

# Convert remaining valid ones to data frame
centrality_df <- as.data.frame(centrality_scores_clean_list)


# Remove columns with NA values
centrality_df_clean <- centrality_df[, colSums(is.na(centrality_df)) == 0]

# Load library
if (!require("factoextra")) install.packages("factoextra")
library(factoextra)

# Perform PCA
pca_res <- prcomp(centrality_df_clean, scale. = TRUE)

# Plot variable contributions
fviz_pca_var(pca_res, col.var = "contrib", repel = TRUE, axes = c(1, 2))

# Get top contributing measure
var_contrib <- get_pca_var(pca_res)$contrib
mean_contrib <- rowMeans(var_contrib[, 1:2])
top_5_measure <- names(sort(mean_contrib, decreasing = TRUE)[1:5])
cat("Top 5 contributing centrality:", top_measure, "\n")
top_measure <- names(sort(mean_contrib, decreasing = TRUE)[1])

# Extract and filter hub genes (HUB genes not identified in this step)
# Print column names
# colnames(centrality_df_clean)

# # Print the top_measure value
# print(top_measure)

# top_scores <- centrality_df_clean[[top_measure]]
# # Define 90th percentile cutoff
# quantile_cutoff <- quantile(top_scores, 0.9)
# # Select top 10%
# hub_genes <- names(top_scores[top_scores >= quantile_cutoff])
# # Output
# print(hub_genes)
# write.table(hub_genes, "hub_genes.txt", row.names = FALSE, col.names = FALSE, quote = FALSE)


# Top 20 genes ranked from centrality measures were saved as CSV files in the temp directory
# these files are generated by cytoscape using the cytohubban plugin and starts with "20"
# Merge top 20 genes from each centrality measure
top20 <- list.files("temp/", pattern = ".csv", full.names = T)
top20 <- top20[1:5]

merged_data <- lapply(top20, function(file) {
  df <- read.csv(file, header = TRUE)
  df
})

final_merged_data <- Reduce(function(x, y) merge(x, y, by = "Name", all = TRUE), merged_data)
final_merged_data <- final_merged_data[!is.na(final_merged_data$Rank.x),]
final_merged_data <- final_merged_data[!is.na(final_merged_data$Score),]
dim(final_merged_data)
# Save the final merged data to a CSV file
write.csv(final_merged_data$Name, "temp/listofHubGenes.csv", row.names = FALSE, quote = FALSE)
